{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten Letter Recognition using PyTorch",
      "provenance": [],
      "authorship_tag": "ABX9TyNhQG4q+Fa6ckOQzGSxzPsO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryankargwal/Handwritten-Letter-Recognition/blob/master/Handwritten_Letter_Recognition_using_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xTBlfhNusoj",
        "colab_type": "text"
      },
      "source": [
        "# Handwritten Letter Recognition \n",
        "In the following code I have tried to recognize handwritten letters using a modified version of the LeNet-5 architecture on the MNIST dataset using PyTorch and have managed to get 99.20% accuracy on the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzugu1vBvC1Y",
        "colab_type": "text"
      },
      "source": [
        "## Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akq8hbCBu1yB",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT531-gIN-Oe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "206c1c5d-de29-4976-f5c4-c2072c15d4df"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDSk-gwth7Vi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f1a7fc7-5fbb-46a3-9208-ea425faeea76"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjrTqMJIh9iY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUSOYue6iAnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! kaggle competitions download -c digit-recognizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDSWFHy4iC3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU5g2TKLiDv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(\"/content/train.csv\") #../input/digit-recognizer/train.csv\n",
        "df_test = pd.read_csv(\"/content/test.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgYcmejliIjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "774dff01-eac5-4a4f-fc46-5e20fec917c6"
      },
      "source": [
        "print(\"Train File\", df_train.shape)\n",
        "print(\"Test File\", df_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train File (42000, 785)\n",
            "Test File (28000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeWddyZXvOq5",
        "colab_type": "text"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CnCS5kZiJMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "outputId": "b2b87be8-38ba-4d89-b87b-f2cb908f61d5"
      },
      "source": [
        "display(\"Train File\", df_train.describe())\n",
        "display(\"Test File\", df_test.describe())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Train File'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.00000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.00000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.00000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.456643</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00300</td>\n",
              "      <td>0.011190</td>\n",
              "      <td>0.005143</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000381</td>\n",
              "      <td>0.001310</td>\n",
              "      <td>0.010548</td>\n",
              "      <td>0.027262</td>\n",
              "      <td>0.050905</td>\n",
              "      <td>0.066405</td>\n",
              "      <td>0.129571</td>\n",
              "      <td>...</td>\n",
              "      <td>3.772524</td>\n",
              "      <td>2.748905</td>\n",
              "      <td>1.796452</td>\n",
              "      <td>1.089905</td>\n",
              "      <td>0.563190</td>\n",
              "      <td>0.239571</td>\n",
              "      <td>0.093524</td>\n",
              "      <td>0.024833</td>\n",
              "      <td>0.000857</td>\n",
              "      <td>0.001405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006143</td>\n",
              "      <td>0.035833</td>\n",
              "      <td>0.082357</td>\n",
              "      <td>0.114905</td>\n",
              "      <td>0.178714</td>\n",
              "      <td>0.301452</td>\n",
              "      <td>0.413643</td>\n",
              "      <td>0.513667</td>\n",
              "      <td>0.558833</td>\n",
              "      <td>0.677857</td>\n",
              "      <td>0.60281</td>\n",
              "      <td>0.489238</td>\n",
              "      <td>0.340214</td>\n",
              "      <td>0.219286</td>\n",
              "      <td>0.117095</td>\n",
              "      <td>0.059024</td>\n",
              "      <td>0.02019</td>\n",
              "      <td>0.017238</td>\n",
              "      <td>0.002857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.887730</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.56812</td>\n",
              "      <td>1.626927</td>\n",
              "      <td>1.053972</td>\n",
              "      <td>0.043916</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.078072</td>\n",
              "      <td>0.232634</td>\n",
              "      <td>1.131661</td>\n",
              "      <td>2.310396</td>\n",
              "      <td>3.121847</td>\n",
              "      <td>3.259128</td>\n",
              "      <td>4.992894</td>\n",
              "      <td>...</td>\n",
              "      <td>26.957829</td>\n",
              "      <td>22.879248</td>\n",
              "      <td>18.595109</td>\n",
              "      <td>14.434439</td>\n",
              "      <td>10.517823</td>\n",
              "      <td>6.469315</td>\n",
              "      <td>3.976306</td>\n",
              "      <td>1.846016</td>\n",
              "      <td>0.139556</td>\n",
              "      <td>0.287891</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.949803</td>\n",
              "      <td>2.350859</td>\n",
              "      <td>3.934280</td>\n",
              "      <td>4.543583</td>\n",
              "      <td>5.856772</td>\n",
              "      <td>7.219742</td>\n",
              "      <td>8.928286</td>\n",
              "      <td>10.004069</td>\n",
              "      <td>10.129595</td>\n",
              "      <td>11.254931</td>\n",
              "      <td>10.69603</td>\n",
              "      <td>9.480066</td>\n",
              "      <td>7.950251</td>\n",
              "      <td>6.312890</td>\n",
              "      <td>4.633819</td>\n",
              "      <td>3.274488</td>\n",
              "      <td>1.75987</td>\n",
              "      <td>1.894498</td>\n",
              "      <td>0.414264</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.00000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>216.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>243.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>177.000000</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.00000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>253.00000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              label   pixel0   pixel1  ...  pixel781  pixel782  pixel783\n",
              "count  42000.000000  42000.0  42000.0  ...   42000.0   42000.0   42000.0\n",
              "mean       4.456643      0.0      0.0  ...       0.0       0.0       0.0\n",
              "std        2.887730      0.0      0.0  ...       0.0       0.0       0.0\n",
              "min        0.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "25%        2.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "50%        4.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "75%        7.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "max        9.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "\n",
              "[8 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Test File'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001357</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.016786</td>\n",
              "      <td>0.031714</td>\n",
              "      <td>0.056000</td>\n",
              "      <td>0.100464</td>\n",
              "      <td>0.166929</td>\n",
              "      <td>...</td>\n",
              "      <td>3.272536</td>\n",
              "      <td>2.371464</td>\n",
              "      <td>1.454357</td>\n",
              "      <td>0.846286</td>\n",
              "      <td>0.509750</td>\n",
              "      <td>0.254750</td>\n",
              "      <td>0.062107</td>\n",
              "      <td>0.015250</td>\n",
              "      <td>0.000786</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005429</td>\n",
              "      <td>0.024179</td>\n",
              "      <td>0.036250</td>\n",
              "      <td>0.083143</td>\n",
              "      <td>0.134107</td>\n",
              "      <td>0.201071</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>0.366714</td>\n",
              "      <td>0.468143</td>\n",
              "      <td>0.589429</td>\n",
              "      <td>0.656964</td>\n",
              "      <td>0.569714</td>\n",
              "      <td>0.464214</td>\n",
              "      <td>0.323679</td>\n",
              "      <td>0.164607</td>\n",
              "      <td>0.073214</td>\n",
              "      <td>0.028036</td>\n",
              "      <td>0.011250</td>\n",
              "      <td>0.006536</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.227093</td>\n",
              "      <td>1.566275</td>\n",
              "      <td>1.513515</td>\n",
              "      <td>2.674449</td>\n",
              "      <td>3.216234</td>\n",
              "      <td>4.549478</td>\n",
              "      <td>5.470524</td>\n",
              "      <td>...</td>\n",
              "      <td>25.211706</td>\n",
              "      <td>21.240003</td>\n",
              "      <td>16.643468</td>\n",
              "      <td>12.637953</td>\n",
              "      <td>9.963879</td>\n",
              "      <td>7.031504</td>\n",
              "      <td>3.040514</td>\n",
              "      <td>1.265562</td>\n",
              "      <td>0.131475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.640468</td>\n",
              "      <td>2.234963</td>\n",
              "      <td>2.493982</td>\n",
              "      <td>3.777711</td>\n",
              "      <td>4.946940</td>\n",
              "      <td>6.262819</td>\n",
              "      <td>7.714814</td>\n",
              "      <td>8.243535</td>\n",
              "      <td>8.974038</td>\n",
              "      <td>10.488695</td>\n",
              "      <td>11.209508</td>\n",
              "      <td>10.204173</td>\n",
              "      <td>9.402197</td>\n",
              "      <td>7.878854</td>\n",
              "      <td>5.473293</td>\n",
              "      <td>3.616811</td>\n",
              "      <td>1.813602</td>\n",
              "      <td>1.205211</td>\n",
              "      <td>0.807475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>236.000000</td>\n",
              "      <td>163.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>245.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>193.000000</td>\n",
              "      <td>187.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        pixel0   pixel1   pixel2  ...  pixel781  pixel782  pixel783\n",
              "count  28000.0  28000.0  28000.0  ...   28000.0   28000.0   28000.0\n",
              "mean       0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "std        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "min        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "25%        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "50%        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "75%        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "max        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "\n",
              "[8 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGQZmuORiKwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "312cbb24-fcf3-40bd-d1cb-14f5375a1db8"
      },
      "source": [
        "sns.countplot(df_train['label'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f213863e1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I4FHs2HvY2R",
        "colab_type": "text"
      },
      "source": [
        "### Train-Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQPDcDCfimIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df_train['label'].values\n",
        "X = df_train.drop(['label'],1).values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfO5PyVRipQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b953be4-2c67-4a9e-c70d-c144b6f3df16"
      },
      "source": [
        "print(y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ4i_WHhveQK",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02r6dYVbvtao",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b7zvpn7i-F7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnFPNCy_v1cT",
        "colab_type": "text"
      },
      "source": [
        "### Separate into labels and training images and reshape the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUtEsluImOub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = df_train['label'].values\n",
        "train_images = (df_train.iloc[:,1:].values).astype('float32')\n",
        "test_images = (df_test.iloc[:,:].values).astype('float32')\n",
        "\n",
        "#Training and Validation Split\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels,\n",
        "                                                                     stratify=train_labels, random_state=123,\n",
        "                                                                     test_size=0.20)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWxdzqFMmYYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28)\n",
        "val_images = val_images.reshape(val_images.shape[0], 28, 28)\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxn2QWstwBko",
        "colab_type": "text"
      },
      "source": [
        "### Convert images to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzcUcY3tmcc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train\n",
        "train_images_tensor = torch.tensor(train_images)/255.0\n",
        "train_labels_tensor = torch.tensor(train_labels)\n",
        "train_tensor = TensorDataset(train_images_tensor, train_labels_tensor)\n",
        "\n",
        "#val\n",
        "val_images_tensor = torch.tensor(val_images)/255.0\n",
        "val_labels_tensor = torch.tensor(val_labels)\n",
        "val_tensor = TensorDataset(val_images_tensor, val_labels_tensor)\n",
        "\n",
        "#test\n",
        "test_images_tensor = torch.tensor(test_images)/255.0"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbC-rTTwwJCa",
        "colab_type": "text"
      },
      "source": [
        "### Load images into the data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DezKlciwmhiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_tensor, batch_size=16, num_workers=2, shuffle=True)\n",
        "val_loader = DataLoader(val_tensor, batch_size=16, num_workers=2, shuffle=True)\n",
        "test_loader = DataLoader(test_images_tensor, batch_size=16, num_workers=2, shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "071emBx-wPRs",
        "colab_type": "text"
      },
      "source": [
        "### Defining Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he_TiQf4m8W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2) \n",
        "        )\n",
        "        \n",
        "        self.linear_block = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(128*7*7, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv_block(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_block(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbXowddgm_-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "e4792912-eaf8-4ae0-c69b-3034c39c5365"
      },
      "source": [
        "conv_model = Net()\n",
        "conv_model"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv_block): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (linear_block): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=6272, out_features=128, bias=True)\n",
              "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Dropout(p=0.5, inplace=False)\n",
              "    (5): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Dropout(p=0.5, inplace=False)\n",
              "    (9): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qWh6RrAwXW2",
        "colab_type": "text"
      },
      "source": [
        "### Define the optimizer and loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_duzrWh-nCRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(params=conv_model.parameters(), lr=0.003)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    conv_model = conv_model.cuda()\n",
        "    criterion = criterion.cuda()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUYc8jciwdC8",
        "colab_type": "text"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dC3e0Y8nHXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(num_epoch):\n",
        "    conv_model.train()\n",
        "    exp_lr_scheduler.step()\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data.unsqueeze(1)\n",
        "        data, target = data, target\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        output = conv_model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (batch_idx + 1)% 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                num_epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
        "                100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
        "            \n",
        "def evaluate(data_loader):\n",
        "    conv_model.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    for data, target in data_loader:\n",
        "        data = data.unsqueeze(1)\n",
        "        data, target = data, target\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "        \n",
        "        output = conv_model(data)\n",
        "        \n",
        "        loss += F.cross_entropy(output, target, size_average=False).item()\n",
        "\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        \n",
        "    loss /= len(data_loader.dataset)\n",
        "        \n",
        "    print('\\nAverage Val Loss: {:.4f}, Val Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
        "        loss, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5GSPq36neUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48377c13-6e44-4fa2-de98-3bab9bea9096"
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for n in range(num_epochs):\n",
        "    train_model(n)\n",
        "    evaluate(val_loader)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [1600/33600 (5%)]\tLoss: 0.914788\n",
            "Train Epoch: 0 [3200/33600 (10%)]\tLoss: 0.335747\n",
            "Train Epoch: 0 [4800/33600 (14%)]\tLoss: 0.243646\n",
            "Train Epoch: 0 [6400/33600 (19%)]\tLoss: 0.275152\n",
            "Train Epoch: 0 [8000/33600 (24%)]\tLoss: 0.575230\n",
            "Train Epoch: 0 [9600/33600 (29%)]\tLoss: 0.294781\n",
            "Train Epoch: 0 [11200/33600 (33%)]\tLoss: 0.441929\n",
            "Train Epoch: 0 [12800/33600 (38%)]\tLoss: 0.240061\n",
            "Train Epoch: 0 [14400/33600 (43%)]\tLoss: 0.174218\n",
            "Train Epoch: 0 [16000/33600 (48%)]\tLoss: 0.394327\n",
            "Train Epoch: 0 [17600/33600 (52%)]\tLoss: 0.256539\n",
            "Train Epoch: 0 [19200/33600 (57%)]\tLoss: 0.140435\n",
            "Train Epoch: 0 [20800/33600 (62%)]\tLoss: 0.988514\n",
            "Train Epoch: 0 [22400/33600 (67%)]\tLoss: 0.154986\n",
            "Train Epoch: 0 [24000/33600 (71%)]\tLoss: 0.345560\n",
            "Train Epoch: 0 [25600/33600 (76%)]\tLoss: 0.043270\n",
            "Train Epoch: 0 [27200/33600 (81%)]\tLoss: 0.655127\n",
            "Train Epoch: 0 [28800/33600 (86%)]\tLoss: 0.331259\n",
            "Train Epoch: 0 [30400/33600 (90%)]\tLoss: 0.183614\n",
            "Train Epoch: 0 [32000/33600 (95%)]\tLoss: 0.497971\n",
            "Train Epoch: 0 [33600/33600 (100%)]\tLoss: 0.556025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average Val Loss: 0.0642, Val Accuracy: 8234/8400 (98.024%)\n",
            "\n",
            "Train Epoch: 1 [1600/33600 (5%)]\tLoss: 0.468318\n",
            "Train Epoch: 1 [3200/33600 (10%)]\tLoss: 0.372624\n",
            "Train Epoch: 1 [4800/33600 (14%)]\tLoss: 0.024437\n",
            "Train Epoch: 1 [6400/33600 (19%)]\tLoss: 0.173822\n",
            "Train Epoch: 1 [8000/33600 (24%)]\tLoss: 1.362533\n",
            "Train Epoch: 1 [9600/33600 (29%)]\tLoss: 0.364603\n",
            "Train Epoch: 1 [11200/33600 (33%)]\tLoss: 0.049464\n",
            "Train Epoch: 1 [12800/33600 (38%)]\tLoss: 0.645423\n",
            "Train Epoch: 1 [14400/33600 (43%)]\tLoss: 0.911551\n",
            "Train Epoch: 1 [16000/33600 (48%)]\tLoss: 0.224738\n",
            "Train Epoch: 1 [17600/33600 (52%)]\tLoss: 1.072144\n",
            "Train Epoch: 1 [19200/33600 (57%)]\tLoss: 0.100497\n",
            "Train Epoch: 1 [20800/33600 (62%)]\tLoss: 0.235826\n",
            "Train Epoch: 1 [22400/33600 (67%)]\tLoss: 0.065826\n",
            "Train Epoch: 1 [24000/33600 (71%)]\tLoss: 0.134915\n",
            "Train Epoch: 1 [25600/33600 (76%)]\tLoss: 0.029356\n",
            "Train Epoch: 1 [27200/33600 (81%)]\tLoss: 0.364782\n",
            "Train Epoch: 1 [28800/33600 (86%)]\tLoss: 0.095822\n",
            "Train Epoch: 1 [30400/33600 (90%)]\tLoss: 0.317009\n",
            "Train Epoch: 1 [32000/33600 (95%)]\tLoss: 0.098867\n",
            "Train Epoch: 1 [33600/33600 (100%)]\tLoss: 0.026414\n",
            "\n",
            "Average Val Loss: 0.0465, Val Accuracy: 8285/8400 (98.631%)\n",
            "\n",
            "Train Epoch: 2 [1600/33600 (5%)]\tLoss: 0.129867\n",
            "Train Epoch: 2 [3200/33600 (10%)]\tLoss: 0.009489\n",
            "Train Epoch: 2 [4800/33600 (14%)]\tLoss: 0.057503\n",
            "Train Epoch: 2 [6400/33600 (19%)]\tLoss: 0.660718\n",
            "Train Epoch: 2 [8000/33600 (24%)]\tLoss: 0.132167\n",
            "Train Epoch: 2 [9600/33600 (29%)]\tLoss: 0.154977\n",
            "Train Epoch: 2 [11200/33600 (33%)]\tLoss: 0.007094\n",
            "Train Epoch: 2 [12800/33600 (38%)]\tLoss: 0.101466\n",
            "Train Epoch: 2 [14400/33600 (43%)]\tLoss: 0.046814\n",
            "Train Epoch: 2 [16000/33600 (48%)]\tLoss: 0.058821\n",
            "Train Epoch: 2 [17600/33600 (52%)]\tLoss: 0.042726\n",
            "Train Epoch: 2 [19200/33600 (57%)]\tLoss: 0.005995\n",
            "Train Epoch: 2 [20800/33600 (62%)]\tLoss: 0.228567\n",
            "Train Epoch: 2 [22400/33600 (67%)]\tLoss: 0.057045\n",
            "Train Epoch: 2 [24000/33600 (71%)]\tLoss: 0.133085\n",
            "Train Epoch: 2 [25600/33600 (76%)]\tLoss: 0.873643\n",
            "Train Epoch: 2 [27200/33600 (81%)]\tLoss: 0.090596\n",
            "Train Epoch: 2 [28800/33600 (86%)]\tLoss: 0.100749\n",
            "Train Epoch: 2 [30400/33600 (90%)]\tLoss: 0.241317\n",
            "Train Epoch: 2 [32000/33600 (95%)]\tLoss: 0.252992\n",
            "Train Epoch: 2 [33600/33600 (100%)]\tLoss: 0.040374\n",
            "\n",
            "Average Val Loss: 0.0396, Val Accuracy: 8314/8400 (98.976%)\n",
            "\n",
            "Train Epoch: 3 [1600/33600 (5%)]\tLoss: 0.047371\n",
            "Train Epoch: 3 [3200/33600 (10%)]\tLoss: 0.085468\n",
            "Train Epoch: 3 [4800/33600 (14%)]\tLoss: 0.276651\n",
            "Train Epoch: 3 [6400/33600 (19%)]\tLoss: 0.064986\n",
            "Train Epoch: 3 [8000/33600 (24%)]\tLoss: 0.083568\n",
            "Train Epoch: 3 [9600/33600 (29%)]\tLoss: 0.019821\n",
            "Train Epoch: 3 [11200/33600 (33%)]\tLoss: 0.515929\n",
            "Train Epoch: 3 [12800/33600 (38%)]\tLoss: 0.002448\n",
            "Train Epoch: 3 [14400/33600 (43%)]\tLoss: 0.202189\n",
            "Train Epoch: 3 [16000/33600 (48%)]\tLoss: 0.026778\n",
            "Train Epoch: 3 [17600/33600 (52%)]\tLoss: 0.028097\n",
            "Train Epoch: 3 [19200/33600 (57%)]\tLoss: 0.267568\n",
            "Train Epoch: 3 [20800/33600 (62%)]\tLoss: 0.215946\n",
            "Train Epoch: 3 [22400/33600 (67%)]\tLoss: 0.044911\n",
            "Train Epoch: 3 [24000/33600 (71%)]\tLoss: 0.223721\n",
            "Train Epoch: 3 [25600/33600 (76%)]\tLoss: 0.060595\n",
            "Train Epoch: 3 [27200/33600 (81%)]\tLoss: 0.324262\n",
            "Train Epoch: 3 [28800/33600 (86%)]\tLoss: 0.064280\n",
            "Train Epoch: 3 [30400/33600 (90%)]\tLoss: 0.552055\n",
            "Train Epoch: 3 [32000/33600 (95%)]\tLoss: 0.355650\n",
            "Train Epoch: 3 [33600/33600 (100%)]\tLoss: 0.110908\n",
            "\n",
            "Average Val Loss: 0.0355, Val Accuracy: 8314/8400 (98.976%)\n",
            "\n",
            "Train Epoch: 4 [1600/33600 (5%)]\tLoss: 0.579891\n",
            "Train Epoch: 4 [3200/33600 (10%)]\tLoss: 0.034025\n",
            "Train Epoch: 4 [4800/33600 (14%)]\tLoss: 0.026764\n",
            "Train Epoch: 4 [6400/33600 (19%)]\tLoss: 0.035046\n",
            "Train Epoch: 4 [8000/33600 (24%)]\tLoss: 0.381212\n",
            "Train Epoch: 4 [9600/33600 (29%)]\tLoss: 0.424308\n",
            "Train Epoch: 4 [11200/33600 (33%)]\tLoss: 0.033450\n",
            "Train Epoch: 4 [12800/33600 (38%)]\tLoss: 0.008687\n",
            "Train Epoch: 4 [14400/33600 (43%)]\tLoss: 0.041147\n",
            "Train Epoch: 4 [16000/33600 (48%)]\tLoss: 0.088394\n",
            "Train Epoch: 4 [17600/33600 (52%)]\tLoss: 0.222170\n",
            "Train Epoch: 4 [19200/33600 (57%)]\tLoss: 0.410970\n",
            "Train Epoch: 4 [20800/33600 (62%)]\tLoss: 0.040034\n",
            "Train Epoch: 4 [22400/33600 (67%)]\tLoss: 0.204240\n",
            "Train Epoch: 4 [24000/33600 (71%)]\tLoss: 0.125137\n",
            "Train Epoch: 4 [25600/33600 (76%)]\tLoss: 0.007135\n",
            "Train Epoch: 4 [27200/33600 (81%)]\tLoss: 0.049780\n",
            "Train Epoch: 4 [28800/33600 (86%)]\tLoss: 0.070294\n",
            "Train Epoch: 4 [30400/33600 (90%)]\tLoss: 0.038046\n",
            "Train Epoch: 4 [32000/33600 (95%)]\tLoss: 0.008273\n",
            "Train Epoch: 4 [33600/33600 (100%)]\tLoss: 0.084077\n",
            "\n",
            "Average Val Loss: 0.0372, Val Accuracy: 8315/8400 (98.988%)\n",
            "\n",
            "Train Epoch: 5 [1600/33600 (5%)]\tLoss: 0.020496\n",
            "Train Epoch: 5 [3200/33600 (10%)]\tLoss: 0.822887\n",
            "Train Epoch: 5 [4800/33600 (14%)]\tLoss: 0.010492\n",
            "Train Epoch: 5 [6400/33600 (19%)]\tLoss: 0.134412\n",
            "Train Epoch: 5 [8000/33600 (24%)]\tLoss: 0.339222\n",
            "Train Epoch: 5 [9600/33600 (29%)]\tLoss: 0.095219\n",
            "Train Epoch: 5 [11200/33600 (33%)]\tLoss: 0.290496\n",
            "Train Epoch: 5 [12800/33600 (38%)]\tLoss: 0.254042\n",
            "Train Epoch: 5 [14400/33600 (43%)]\tLoss: 0.430054\n",
            "Train Epoch: 5 [16000/33600 (48%)]\tLoss: 0.012583\n",
            "Train Epoch: 5 [17600/33600 (52%)]\tLoss: 0.273354\n",
            "Train Epoch: 5 [19200/33600 (57%)]\tLoss: 0.009851\n",
            "Train Epoch: 5 [20800/33600 (62%)]\tLoss: 0.081755\n",
            "Train Epoch: 5 [22400/33600 (67%)]\tLoss: 0.029983\n",
            "Train Epoch: 5 [24000/33600 (71%)]\tLoss: 0.029053\n",
            "Train Epoch: 5 [25600/33600 (76%)]\tLoss: 0.014859\n",
            "Train Epoch: 5 [27200/33600 (81%)]\tLoss: 0.129343\n",
            "Train Epoch: 5 [28800/33600 (86%)]\tLoss: 0.263263\n",
            "Train Epoch: 5 [30400/33600 (90%)]\tLoss: 0.633675\n",
            "Train Epoch: 5 [32000/33600 (95%)]\tLoss: 0.016436\n",
            "Train Epoch: 5 [33600/33600 (100%)]\tLoss: 0.026354\n",
            "\n",
            "Average Val Loss: 0.0343, Val Accuracy: 8316/8400 (99.000%)\n",
            "\n",
            "Train Epoch: 6 [1600/33600 (5%)]\tLoss: 0.024440\n",
            "Train Epoch: 6 [3200/33600 (10%)]\tLoss: 0.286509\n",
            "Train Epoch: 6 [4800/33600 (14%)]\tLoss: 0.049304\n",
            "Train Epoch: 6 [6400/33600 (19%)]\tLoss: 0.001477\n",
            "Train Epoch: 6 [8000/33600 (24%)]\tLoss: 0.013754\n",
            "Train Epoch: 6 [9600/33600 (29%)]\tLoss: 0.050772\n",
            "Train Epoch: 6 [11200/33600 (33%)]\tLoss: 0.248635\n",
            "Train Epoch: 6 [12800/33600 (38%)]\tLoss: 0.044362\n",
            "Train Epoch: 6 [14400/33600 (43%)]\tLoss: 0.017729\n",
            "Train Epoch: 6 [16000/33600 (48%)]\tLoss: 0.020168\n",
            "Train Epoch: 6 [17600/33600 (52%)]\tLoss: 0.029793\n",
            "Train Epoch: 6 [19200/33600 (57%)]\tLoss: 0.461197\n",
            "Train Epoch: 6 [20800/33600 (62%)]\tLoss: 0.049199\n",
            "Train Epoch: 6 [22400/33600 (67%)]\tLoss: 0.002193\n",
            "Train Epoch: 6 [24000/33600 (71%)]\tLoss: 0.008771\n",
            "Train Epoch: 6 [25600/33600 (76%)]\tLoss: 0.208425\n",
            "Train Epoch: 6 [27200/33600 (81%)]\tLoss: 0.387343\n",
            "Train Epoch: 6 [28800/33600 (86%)]\tLoss: 0.013950\n",
            "Train Epoch: 6 [30400/33600 (90%)]\tLoss: 0.005396\n",
            "Train Epoch: 6 [32000/33600 (95%)]\tLoss: 0.017294\n",
            "Train Epoch: 6 [33600/33600 (100%)]\tLoss: 0.004502\n",
            "\n",
            "Average Val Loss: 0.0296, Val Accuracy: 8324/8400 (99.095%)\n",
            "\n",
            "Train Epoch: 7 [1600/33600 (5%)]\tLoss: 0.031079\n",
            "Train Epoch: 7 [3200/33600 (10%)]\tLoss: 0.071275\n",
            "Train Epoch: 7 [4800/33600 (14%)]\tLoss: 0.082570\n",
            "Train Epoch: 7 [6400/33600 (19%)]\tLoss: 0.155509\n",
            "Train Epoch: 7 [8000/33600 (24%)]\tLoss: 0.155651\n",
            "Train Epoch: 7 [9600/33600 (29%)]\tLoss: 0.005481\n",
            "Train Epoch: 7 [11200/33600 (33%)]\tLoss: 0.316136\n",
            "Train Epoch: 7 [12800/33600 (38%)]\tLoss: 0.033541\n",
            "Train Epoch: 7 [14400/33600 (43%)]\tLoss: 0.151074\n",
            "Train Epoch: 7 [16000/33600 (48%)]\tLoss: 0.917981\n",
            "Train Epoch: 7 [17600/33600 (52%)]\tLoss: 0.035802\n",
            "Train Epoch: 7 [19200/33600 (57%)]\tLoss: 0.180242\n",
            "Train Epoch: 7 [20800/33600 (62%)]\tLoss: 0.095360\n",
            "Train Epoch: 7 [22400/33600 (67%)]\tLoss: 0.069019\n",
            "Train Epoch: 7 [24000/33600 (71%)]\tLoss: 0.019972\n",
            "Train Epoch: 7 [25600/33600 (76%)]\tLoss: 0.148363\n",
            "Train Epoch: 7 [27200/33600 (81%)]\tLoss: 0.015809\n",
            "Train Epoch: 7 [28800/33600 (86%)]\tLoss: 0.044820\n",
            "Train Epoch: 7 [30400/33600 (90%)]\tLoss: 0.053870\n",
            "Train Epoch: 7 [32000/33600 (95%)]\tLoss: 0.080556\n",
            "Train Epoch: 7 [33600/33600 (100%)]\tLoss: 0.195076\n",
            "\n",
            "Average Val Loss: 0.0276, Val Accuracy: 8338/8400 (99.262%)\n",
            "\n",
            "Train Epoch: 8 [1600/33600 (5%)]\tLoss: 0.301795\n",
            "Train Epoch: 8 [3200/33600 (10%)]\tLoss: 0.275240\n",
            "Train Epoch: 8 [4800/33600 (14%)]\tLoss: 0.019780\n",
            "Train Epoch: 8 [6400/33600 (19%)]\tLoss: 0.022125\n",
            "Train Epoch: 8 [8000/33600 (24%)]\tLoss: 0.115411\n",
            "Train Epoch: 8 [9600/33600 (29%)]\tLoss: 0.027923\n",
            "Train Epoch: 8 [11200/33600 (33%)]\tLoss: 0.046516\n",
            "Train Epoch: 8 [12800/33600 (38%)]\tLoss: 0.400334\n",
            "Train Epoch: 8 [14400/33600 (43%)]\tLoss: 0.086353\n",
            "Train Epoch: 8 [16000/33600 (48%)]\tLoss: 0.005057\n",
            "Train Epoch: 8 [17600/33600 (52%)]\tLoss: 0.039147\n",
            "Train Epoch: 8 [19200/33600 (57%)]\tLoss: 0.301877\n",
            "Train Epoch: 8 [20800/33600 (62%)]\tLoss: 0.040888\n",
            "Train Epoch: 8 [22400/33600 (67%)]\tLoss: 0.085451\n",
            "Train Epoch: 8 [24000/33600 (71%)]\tLoss: 0.015258\n",
            "Train Epoch: 8 [25600/33600 (76%)]\tLoss: 0.023567\n",
            "Train Epoch: 8 [27200/33600 (81%)]\tLoss: 0.044688\n",
            "Train Epoch: 8 [28800/33600 (86%)]\tLoss: 0.112193\n",
            "Train Epoch: 8 [30400/33600 (90%)]\tLoss: 0.075959\n",
            "Train Epoch: 8 [32000/33600 (95%)]\tLoss: 0.018272\n",
            "Train Epoch: 8 [33600/33600 (100%)]\tLoss: 0.025635\n",
            "\n",
            "Average Val Loss: 0.0274, Val Accuracy: 8333/8400 (99.202%)\n",
            "\n",
            "Train Epoch: 9 [1600/33600 (5%)]\tLoss: 0.016301\n",
            "Train Epoch: 9 [3200/33600 (10%)]\tLoss: 0.012977\n",
            "Train Epoch: 9 [4800/33600 (14%)]\tLoss: 0.049475\n",
            "Train Epoch: 9 [6400/33600 (19%)]\tLoss: 0.031398\n",
            "Train Epoch: 9 [8000/33600 (24%)]\tLoss: 0.393372\n",
            "Train Epoch: 9 [9600/33600 (29%)]\tLoss: 0.015618\n",
            "Train Epoch: 9 [11200/33600 (33%)]\tLoss: 0.009460\n",
            "Train Epoch: 9 [12800/33600 (38%)]\tLoss: 0.085230\n",
            "Train Epoch: 9 [14400/33600 (43%)]\tLoss: 0.302016\n",
            "Train Epoch: 9 [16000/33600 (48%)]\tLoss: 0.028568\n",
            "Train Epoch: 9 [17600/33600 (52%)]\tLoss: 0.001051\n",
            "Train Epoch: 9 [19200/33600 (57%)]\tLoss: 0.028369\n",
            "Train Epoch: 9 [20800/33600 (62%)]\tLoss: 0.057246\n",
            "Train Epoch: 9 [22400/33600 (67%)]\tLoss: 0.034997\n",
            "Train Epoch: 9 [24000/33600 (71%)]\tLoss: 0.044726\n",
            "Train Epoch: 9 [25600/33600 (76%)]\tLoss: 0.094911\n",
            "Train Epoch: 9 [27200/33600 (81%)]\tLoss: 0.039233\n",
            "Train Epoch: 9 [28800/33600 (86%)]\tLoss: 0.144847\n",
            "Train Epoch: 9 [30400/33600 (90%)]\tLoss: 0.008348\n",
            "Train Epoch: 9 [32000/33600 (95%)]\tLoss: 0.093306\n",
            "Train Epoch: 9 [33600/33600 (100%)]\tLoss: 0.011108\n",
            "\n",
            "Average Val Loss: 0.0273, Val Accuracy: 8333/8400 (99.202%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KShQTDsqpTod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}